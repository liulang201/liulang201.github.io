---
layout:     post
title:      超分辨率论文：Image Super-Resolution Using Deep Convolutional Networks
subtitle:   SRCNN
date:       2019-05-22
author:     刘浪
header-img: img/post-bg-universe.jpg
catalog: true
tags:
    - 计算机视觉
    - deeplearning
    - 超分辨
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

## **Image Super-Resolution Using Deep Convolutional Networks**

### **摘要**

提出了一种单图像超分辨率(SR)的深度学习方法。我们的方法直接学习低/高分辨率图像之间的端到端映射。该映射表示为一个深卷积神经网络(CNN)，**它以低分辨率图像为输入输出高分辨率图像**。我们进一步证明了传统的稀疏编码SR方法也可以看作是一个深卷积网络。但是，与单独处理每个组件的传统方法不同，我们的方法联合优化所有层。我们的深度CNN具有轻量级的结构，但展示了最先进的恢复质量，并实现了快速的实际在线使用。我们探索不同的网络结构和参数设置，以实现性能和速度之间的权衡。此外，我们扩展了我们的网络，同时处理三个颜色通道，并显示出更好的整体重建质量。

超分辨率（super resolution）的任务目标是将输入的低分辨率的图像转换为高分辨率的图像，与图像去噪、图像去模糊等一脉相承。个人认为：超分辨率关注的是从小尺寸到大尺寸图像如何填充新的像素；图像去噪则是关注在图像尺寸不变的情况下，将被“污染”的像素替换为正确的像素。

### **介绍**

单图像超分辨率(SR)是计算机视觉领域的一个经典问题，其目的是将高分辨率图像从低分辨率图像中恢复出来。这个问题本质上是不适定的，**因为对于任何给定的低分辨率像素都存在多种解**。换句话说，它是一个欠定逆问题，其解不是唯一的。**通过使用强先验信息约束解决方案空间，通常可以缓解此类问题**。为了学习之前的方法，目前最先进的方法大多采用**基于实例**的策略。这些方法要么**利用相同图像的内部相似性**，要么从外部低分辨率样本对学习映射函数。基于外部实例的方法可以用于一般的图像超分辨率，也可以设计成适合领域特定任务的方法，即，根据提供的训练样本，出现了面部幻觉

基于稀疏编码的方法是具有代表性的基于外部实例的SR方法之一。该方法在其解决方案管道中涉及几个步骤。

+ 首先，从输入图像中密集裁剪重叠的patch并进行预处理(例如，减去平均值和归一化)。
+ 然后用低分辨率字典对这些patch进行编码。将稀疏系数传递到高分辨率字典中，重建高分辨率斑块。将重叠重建的patch进行聚合(例如，通过加权平均)，生成最终的输出。

这个管道被大多数外部基于实例的方法共享，这些方法特别注重对字典的学习和优化，或者构建高效的映射函数。然而，管道中的其余步骤很少在统一的优化框架中进行优化或考虑。在本文中，我们证明了上述管道相当于一个深度卷积神经网络。基于这一事实，我们考虑一个卷积神经网络，它可以直接学习低分辨率和高分辨率图像之间的端到端映射。我们的方法与现有的基于实例的外部方法有根本的不同，因为我们没有显式地学习字典或流形来建模补丁空间。这些都是通过隐藏层隐式实现的。此外，patch的提取和聚集也被表示为卷积层，因此涉及到优化。在我们的方法中，整个SR管道都是通过学习得到的，几乎没有预处理/后处理。

我们将提出的模型命名为超分辨率卷积神经网络(SRCNN)。提出的的SRCNN有几个吸引人的特性。首先，它的结构是有意设计的简单，但与最先进的基于实例的方法相比，它提供了更高的精确度。下图显示了一个示例的比较。其次，通过适当的滤波器和层数，我们的方法实现了快速的实际在线使用，甚至在CPU上。我们的方法比许多基于实例的方法更快，因为它是完全前馈的，不需要在使用上解决任何优化问题。第三，实验表明，当有更大、更多样化的数据集可用，或使用更大、更深层次的模型时，网络的恢复质量可以进一步提高。相反，较大的数据集/模型可能对现有的基于实例的方法提出挑战。此外，该网络可以同时处理三种彩色图像通道，提高了超分辨率性能。

![](/img/image_process/54.png)

总体而言，本研究的贡献主要体现在三个方面:

+ 提出了一种图像超分辨率全卷积神经网络。网络直接学习低分辨率和高分辨率图像之间的端到端映射，除了优化之外几乎没有什么预处理/后处理。
+ 我们建立了基于深度编码的SR方法与传统的基于稀疏编码的SR方法之间的关系。这种关系为网络结构的设计提供了指导。
+ 我们证明了深度学习在经典的超分辨率计算机视觉问题中是有用的，可以达到良好的质量和速度。

这项工作的初步版本是在之前提出的。目前的工作在很大程度上增加了最初的版本。首先，我们在非线性映射层中引入更大的滤波尺寸来改进SRCNN，并通过增加非线性映射层来探索更深层次的结构。其次，我们将SRCNN扩展到同时处理三个颜色通道(在YCbCr或RGB颜色空间中)。实验表明，与单通道网络相比，该网络的性能有较大的提高。第三，在初步结果中加入了大量新的分析和直观的解释。我们还将原始实验从Set5和Set14测试图像扩展到BSD200(200张测试图像)。此外，我们与最近发布的一些方法进行了比较，并确认我们的模型仍然优于使用不同评估指标的现有方法。

### **应用于CNN的超分辨率**

https://blog.csdn.net/loadqian/article/details/80626438

使用双三次插值将单幅低分辨率图像变成我们想要的大小，假设这个内插值的图像为Y,我们的目标是从Y中恢复图像F（Y）使之尽可能与高分辨率图像X相似，为了便于区分，我们仍然把Y称为低分辨率图像，尽管它与X大小相同，我们希望学习到这个映射函数F，需要以下三步： 

（1）特征提取：从低分辨率图像Y中提取patches，每个patch作为一个高维向量，这些向量组成一个特征映射，其大小等于这些向量的维度。 
公式：第一层定义为函数F1：
$$
F_{1}(\mathbf{Y})=\max \left(0, W_{1} * \mathbf{Y}+B_{1}\right)
$$

其中，W1和B1分别代表滤波器和偏差，W1的大小为$c \times f_{1} \times f_{1}$, c 是输入图像的通道数，f1是滤波器的空间大小，n1是滤波器的数量。从直观上看，W1使用n1个卷积，每个卷积核大小为$c \times f_{1} \times f_{1}$。输出是n1给特征映射。B1是一个n1维的向量，每个元素都与一个滤波器有关，在滤波器响应中使用Rectiﬁed Linear Unit (ReLU,max(0,x)) 

（2）非线性映射： 这个操作将一个高维向量映射到另一个高维向量，每一个映射向量表示一个高分辨率patch,这些向量组成另一个特征映射。 
公式： 第二步将n1维的向量映射到n2维，这相当于使用n2个1*1的滤波器，第二层的操作如下： 
$$
F_{2}(\mathbf{Y})=\max \left(0, W_{2} * F_{1}(\mathbf{Y})+B_{2}\right)
$$

其中，W2的大小为n1*1*1*n2,B2是n2维的向量，每个输出的n2维向量都表示一个高分辨率块（patch）用于后续的重建。 
当然，也可以添加更多的卷积层（1*1的）来添加非线性特征，但会增加模型的复杂度，也需要更多的训练数据和时间，在本文中，我们采用单一的卷积层，因为它已经能取得较好的效果。 

（3）重建： 这个操作汇聚所有的高分辨率patch构成最够的高分辨率图像，我们期望这个图像能与X相似。 
公式： 在传统的方法中，预测的重叠高分辨率块经常取平均后得到最后的图像，这个平均化可以看作是预先定义好的用于一系列特征映射的滤波器（每个位置都是高分辨率块的“扁平”矢量形式），因此，我们定义一个卷积层产生最后的超分辨率图像： 
$$
F(\mathbf{Y})=W_{3} * F_{2}(\mathbf{Y})+B_{3}
$$
W3的大小为$n_{2} \times f_{3} \times f_{3}$，B3是一个c维向量。 如果这个高分辨率块都在图像域，我们把这个滤波器当成均值滤波器；如果这些高分辨率块在其他域，则W3首先将系数投影到图像域然后再做均值，无论哪种情况，W3都是一个线性滤波器。 将这三个操作整合在一起就构成了卷积神经网络，在这个模型中，所有的滤波器权重和偏差均被优化，网络结构如上图：

![](/img/image_process/55.png)

2.2 与基于稀疏编码方法的关系
基于稀疏编码的图像超分辨率方法也可以看作是一个卷积神经网络，在稀疏编码方法中，假设f1*f1大小的低分辨率块是从输入图像中提取的，这一小块减去它的均值，然后投影成一个低分辨率的字典，如果这个字典大小为n1，就等价于对输入图像使用n1个线性滤波器（f1*f1）(减去均值也是一个线性操作，所以可以被吸收)，这部分在上图左半部分中可以看到。 
接下来，稀疏编码器将n1个系数投影输出n2个系数，通常n1=n2，这n2个系数代表高分辨率块，从这个角度看，稀疏编码器表现得像一个非线性映射操作，这部分在上图中间呈现。然而，这个稀疏编码器不是前馈形式，它是一个迭代算法。相反，我们的非线性操作是前反馈的而且可以高效计算，可以认为是一个全连接层。 
上述得n2个系数被投影到另一个高分辨率字典，产生一个高分辨率块，所有重叠的块取平均。这等价于对n2个特征映射的线性卷积。假设这些用于重建的高分辨率小块大小为f3*f3,则线性滤波器也有相同的大小f3*f3，看上图中的右半部分。 
上述讨论展示了基于稀疏编码的SR方法可以看成是一种卷积神经网络（非线性映射不同），但在稀疏编码中，被不是所有的操作都有优化，而卷积神经网络中，低分辨率字典、高分辨率字典、非线性映射，以及减去均值和求平均值等经过滤波器进行优化，所以我们的方法是一种端对端的映射。 
上述分析帮助我们决定超参数，我们设置最后一层滤波器尺寸小于第一层，这样可以更多地依赖于高分辨率块的中心部分，如果f3=1,那么中心的像素不能进行平均。一般设置n2

2.3损失函数

学习端对端的映射函数F需要评估以下参数：$\theta = \left\{W_{1}, W_{2}, W_{3}, B_{1}, B_{2}, B_{3}\right\}$。最小化重建函数$F(\mathbf{Y} ; \Theta)$与对于的高分辨率图像X之间的损失，给出一组高分辨率图像 {Xi} 和对应得低分辨率图像 {Yi}，使用 均方误差（Mean Squared Error，MSE)作为损失函数：

$$
L(\Theta)=\frac{1}{n} \sum_{i=1}^{n}\left\|F\left(\mathbf{Y}_{i} ; \Theta\right)-\mathbf{X}_{i}\right\|^{2}
$$

其中，n为训练样本数，损失的最小化使用随即梯度下降法和标准的BP算法进行反向传播。 使用MSE作为损失函数有利于得到较高的PSNR值，PSNR是图像复原方法中一个常用的评价指标。