---
layout:     post
title:      AutoML综述
subtitle:   AutoML综述
date:       2019-05-13
author:     刘浪
header-img: img/post-bg-universe.jpg
catalog: true
tags:
    - 计算机视觉
    - deeplearning
    - AutoML
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

参考：[AutoML综述](https://arxiv.org/abs/1810.13306)

深度学习模型在很多任务上都取得了不错的效果，但调参对于深度模型来说是一项非常苦难的事情，众多的超参数和网络结构参数会产生爆炸性的组合，常规的 **random search** 和 **grid search** 效率非常低，因此最近几年神经网络的架构搜索和超参数优化成为一个研究热点

机器学习技术已经深深扎根于我们的日常生活中。然而，由于追求良好的学习性能是知识和劳动密集型的，人类专家大量参与机器学习的各个方面。为了使机器学习技术更易于应用，减少对有经验的人类专家的需求，自动化机器学习(AutoML)已经成为一个工业和学术界都感兴趣的热门话题。本文对自动机进行了最新的研究。首先，我们介绍并定义了AutoML问题，并从自动化和机器学习两个领域得到了启发。然后，我们提出了一个通用的AutoML框架，它不仅涵盖了大多数现有的方法，而且可以指导新方法的设计。随后，我们从两个方面对现有作品进行了分类和梳理。，问题设置和使用的技术。最后，我们对AutoML方法进行了详细的分析，并解释了它们成功应用程序背后的原因。我们希望这项调查不仅可以作为一个深刻的指南，为AutoML初学者，也为未来的研究启发。

## 介绍

米切尔著名的机器学习课本是以这样一句话开头的:自从计算机被发明以来，我们一直在想它们是否可以被用来学习。如果我们能够理解如何通过编程让他们学习——通过经验自动提高——影响将是巨大的。这一探索产生了一个新的研究领域，即，机器学习，几十年前的计算机科学。到目前为止，机器学习技术已经深深扎根于我们的日常生活中，比如当我们阅读新闻时的推荐和当我们使用手机时的手写识别。此外，机器学习也取得了显著的成就。例如AlphaGO在围棋比赛中击败人类冠军，ResNet在图像识别方面超越人类，微软语音系统在语音转录方面接近人类水平。

然而，这些机器学习的成功应用远不是完全自动化的，例如"凭经验自动提高"。由于"没有一种算法可以在所有可能的学习问题上取得同等重要的性能"(根据没有免费的午餐定理)，机器学习应用程序的每个方面，如特征工程、模型选择和算法选择(图1)，都需要仔细配置。因此，人类专家大量参与机器学习应用。由于这些专家是稀有资源，机器学习的成功付出了巨大的代价。因此，自动化机器学习(AutoML)不仅像Michell的书中描述的那样是一个学术梦想，而且吸引了更多的实践者的注意。如果我们能够将人从这些机器学习应用程序中分离出来，我们就能够在组织之间更快地部署机器学习解决方案，有效地验证和基准化已部署解决方案的性能，并使专家更多地关注具有更多应用程序和业务价值的问题。这将使机器学习更易于在现实世界中使用，从而带来新的能力和定制水平，其影响确实可能是巨大的。在上述学术梦想和实践需求的推动下，近年来AutoML作为机器学习的一个新的子领域应运而生。它不仅受到机器学习的重视，而且受到计算机视觉、数据挖掘和自然语言处理的重视。到目前为止，AutoML已经成功地应用于许多重要问题(表1)。

![](/img/image_process/29.png)

    图1.为了使用机器学习技术并获得良好的性能，通常需要人类参与数据收集、特征工程、模型和算法选择。这张图展示了一个典型的机器学习应用程序pipeline，以及AutoML如何参与管道并将人类的参与最小化。

![](/img/image_process/30.png)


第一个例子是Auto-sklearn。由于**不同的分类器适用于不同的学习问题**，所以在一个新的问题上尝试一组分类器，然后根据它们构建最终的预测是很自然的。然而，设置分类器及其超参数是一项单调乏味的任务，通常需要人工参与。基于流行的scikit-learn machine learning library， **Auto-sklearn可以通过搜索合适的模型并优化相应的超参数**，自动从一些开箱即用的机器学习工具中找到适合分类的模型。第二个例子是神经结构搜索(NAS)。自从AlexNet在ImageNet数据集的图像分类上取得成功以来，架构设计已经成为深度学习领域性能提升的主要来源。例如VGGNet、GoogleNet、ResNet和DenseNet。因此，对于手头的任务，神经结构的自动设计对于良好的学习性能是非常重要的。许多研究者一直致力于NAS的研究，。此外，NAS已经被应用到谷歌Cloud AutoML中，使客户从困难和耗时的架构设计过程中解放出来。最后一个例子是**自动化特性工程**。在传统的机器学习方法中，建模性能在很大程度上取决于特征的质量。因此，大多数机器学习应用程序都将**特征工程**作为一个重要的步骤，在这个步骤中生成或选择有用的特征。在过去，这类操作通常是由具有深入领域知识的人工专家以反复试验的方式手工完成的。自动特征工程的目标是构建一个新的特征集，利用它可以提高后续机器学习工具的性能。通过这种方法，密集的人类知识和劳动可以节省。现有的研究工作包括Data Science Machine (DSM)、ExploreKit和FeatureHub。此外，我们还看到了一些商业产品，如FeatureLabs。

随着AutoML在科研和行业上的快速发展，我们觉得有必要对现有的工作进行总结，并在这个时候对这个课题进行调查。首先，我们讨论什么是自动问题。然后，我们提出了一个通用框架，总结了现有的方法是如何对AutoML工作的。这样的框架进一步促使我们根据(通过问题设置)什么以及(通过技术)如何自动化来对现有的工作进行分类。具体来说，问题设置帮助我们明确我们想要使用什么学习过程，而技术为我们提供了在相应设置下解决AutoML问题的技术方法和细节。基于这些分类，我们进一步给出了如何开发AutoML方法的指导。

**Contributions**

以下是我们的调查总结:

我们讨论了**AutoML的形式化定义**。这个定义不仅足够通用，可以包含所有现有的AutoML问题，而且足够具体，可以阐明AutoML的目标是什么。这样的定义有助于确定未来AutoML领域的研究目标。我们为现有的AutoML方法提出了一个通用框架。**该框架不仅有助于对现有作品进行分类，而且对现有方法想要解决的问题提出了见解**。这种框架可以作为开发新方法的指导。我们根据“自动化什么”和“如何自动化”对现有的AutoML工作进行了系统的分类。问题设置是从“什么”的角度进行的，这表明我们想要使哪个学习过程自动化。技术是从“如何”的角度，介绍了**解决自动化问题的方法**。对于每个类别，我们提供了详细的应用程序场景供参考。与现有的AutoML相关调查相比，我们基于所提出的框架对现有技术进行了详细的分析。我们不仅调查了更全面的现有工作，但也提出了一个总结的洞察力背后的每一种技术。这不仅可以作为一个很好的指南，初学者的使用，并为未来的研究。从问题的设置、技术、应用和理论等方面，提出了自动化领域四个有前景的研究方向。针对每一个问题，我们都对其在当前工作中的不足进行了深入的分析，并提出了未来的研究方向

调查的组织如下。第2节概述了AutoML的定义，提出了AutoML方法的框架，并通过问题设置和现有工作的技术对其进行分类。第3节通过问题设置描述了分类，第4-6节详细介绍了技术。表1中列出的三个应用示例将在第7节中详细介绍。第8节对调查进行了总结，简要介绍了调查的历史、现状以及对未来工作的讨论。最后，我们在第9节中总结了调查结果。

在接下来的调查中,我们表示机器学习工具$F(\mathrm{x} ; \theta)$,其中x是训练所学到的模型参数和$\theta$**包含配置的学习工具**。此外，调查中最重要的概念解释如下。

+ 学习过程是机器学习管道的一部分或全部。学习过程的例子有**特征工程、模型和/或算法选择**，以及**神经结构设计**。
+ 学习工具是解决机器学习中出现的一些问题的一种方法。例如，支持向量机(SVM)模型是一种学习工具，可以解决特定的分类问题;和稀疏编码也是一种学习工具，可以解决特定类型数据的特征学习问题。
+ 我们使用配置这个术语来表示所有影响学习工具性能的因素，但模型参数x(通常从模型训练中获得)除外。配置的例子有，模型的假设类，模型使用的特征，控制训练过程的超参数，以及神经网络的结构。

## 2 AutoML的定义

在第1节中，我们展示了为什么需要使用AutoML。在本节中，我们首先在2.1节中定义什么是AutoML问题。然后，在第2.2节中，我们提出了一个框架，一般来说，如何解决自动化问题。最后，在第2.3节中给出了基于要自动化什么以及如何自动化的现有工作的分类。

### 2.1 Problem Definition

受自动化和机器学习的启发，我们在这里定义了什么是自动化问题。在此基础上，阐述了AutoML的核心目标。

#### 2.1.1 **AutoML从两个角度**

从它的名字，我们可以看到AutoML自然是自动化和机器学习的交集。虽然自动化有着悠久的历史，甚至可以追溯到公元前年，但是机器学习只是在几十年前才被发明出来。这两个领域的结合，近年来才成为一个热门的研究课题。这两个领域的关键思想及其对AutoML的影响如下。


如定义1所示，机器学习由E、T和P指定，即，当接收到训练数据E时，试图提高其在以P为度量的任务T上的性能。

**Definition 1 (Machine learning)**:如果一个计算机程序的性能可以通过P度量的E对T的度量得到提高，那么它就可以从E对某些任务T和性能度量P的经验中学习

从这个角度来看，AutoML本身也可以看作是一个具有良好泛化性能的学习工具(即，P)输入数据(即，E)和给定的任务(即T,)，传统的机器学习研究更多地关注于发明和分析学习工具，而不是关注这些工具使用起来有多容易。一个这样的例子就是最近从简单到深入模型的趋势，它可以提供更好的性能，但也很难配置。相反，AutoML强调学习工具的易用性。图2说明了这个想法。

![](/img/image_process/31.png)

另一方面，自动化是使用各种控制系统在构建块下运行。为了更好地预测性能，机器学习工具的配置应该适应具有输入数据的任务，这些数据通常是手工执行的。如图3所示，从这个角度来看，AutoML的目标是在学习工具的底层构建高级控制方法，以便在没有人工帮助的情况下找到合适的配置。

![](/img/image_process/32.png)

这两个角度是我们在后续文章中定义AutoML的主要动机。

#### 2.1.2 **The Definition of AutoML**

从上面可以看出，AutoML不仅想要有良好的学习性能(从机器学习的角度)，而且需要在没有人工帮助的情况下实现这种性能(从自动化的角度)。因此，AutoML的非正式和直观的描述可以表示为：

![](/img/image_process/33.png)

更正式地说，我们在定义2中描述了AutoML。这样的定义受到定义1的启发，而AutoML本身也可以看作是另一种机器学习方法(图2)

**Definition 2 (AutoML).**：AutoML试图构建机器学习程序(由定义1中的E、T和P指定)，没有人力的帮助和有限的计算预算。

表2是经典机器学习和AutoML的比较。在经典的机器学习中，人类主要通过操作特征工程、模型选择和算法选择来配置学习工具。因此，人类在机器学习实践中承担了最多的劳动和知识密集型工作。然而，在AutoML中，所有这些都可以通过计算机程序来完成。为了更好地理解定义2，让我们回头看看表1中的三个例子

![](/img/image_process/34.png)

**自动化特性工程(Automated feature engineering)**:当原始特征的信息量不足时，我们可能需要构建更多的特征来提高学习性能。在这种情况下，E是原始特征，T是特征的构造，P是用构造的特征学习模型的性能。DSM和ExploreKit通过基于输入特性之间的交互自动构建新特性来删除人工辅助。

**自动选择模型(Automated model selection)**:这里，E表示输入训练数据，T为分类任务，P为给定任务的性能。当给定特征时，自动sklearn可以选择合适的分类器并在没有人工帮助的情况下找到相应的超参数。

**Neural architecture search (NAS):**当我们试图借助NAS做一些图像分类问题时，E是图像的集合，T是图像分类问题，P是测试图像的性能。NAS将自动搜索神经结构，即，一种基于神经网络的分类器，对给定的任务具有良好的分类性能。

最后，请注意，定义2足够通用，可以涵盖大多数可以认为是自动的机器学习方法。根据这个定义，一个固定配置的机器学习pipeline，不适应不同的E、T和P，也是自动的。这类方法虽然不需要人工帮助，但其默认性能和应用程序范围相当有限。因此，他们不会在续集中继续追求。从上面的讨论中，我们可以看出，虽然人们总是希望获得良好的学习性能，但是AutoML对学习性能的要求可以通过一种更特殊的方式获得，即不需要人工帮助，并且计算预算有限。这些为AutoML设置了三个主要目标

**Remark 2.1 (Core goals).**AutoML的三个目标:

(A)良好的性能:可以在各种输入数据和学习任务方面取得良好的泛化成绩;
(B)无人协助:机器学习工具的配置可以自动完成;
(C)计算效率高:程序可以在有限的预算内返回合理的输出。

由于AutoML本身可以看作是一个机器学习工具(图2)，因此我们在这里指出，目标(a)实际上是为了摆脱臭名昭著的“没有免费午餐”定理的诅咒。这些定理表明，在无噪声的监督学习场景中，所有学习算法在对所有可能的学习任务求平均值时具有相同的泛化性能(错误率)。虽然这些定理在数学上得到了证明，但很难(甚至不可能)将它们应用于现实并进行实证检验。这是因为所有可能的学习任务(同等权重)的平均表现都非常残酷。在所有理论上可能的任务中，学习任务在现实中只占非常小的范围，这是非常可能的。

一旦实现了上述三个目标，我们就可以跨组织快速部署机器学习解决方案，快速验证和基准化已部署解决方案的性能，并让人类更多地关注真正需要人类参与的问题，即、问题定义、数据收集和部署，如图1所示。所有这些都使得机器学习更容易应用，更容易为每个人所用。

#### **2.2 Basic Framework**

然而，在此之前，让我们了解配置是如何由人类进行调优的。如图4所示。一旦一个学习问题被定义，我们需要找到一些学习工具来解决它。这些工具位于图4的右侧，它们可以针对管道的不同部分，即、特征、模型或优化，如图1所示。为了获得良好的学习性能，我们将尝试使用我们对底层数据和工具的个人经验或直觉来设置配置。然后，根据对学习工具执行情况的反馈，我们将调整配置，希望能够提高性能。一旦达到了预期的性能或计算预算耗尽，这种反复试验的过程就会终止。

![](/img/image_process/35.png)

**提出AutoML框架**

受上述涉及到人的流程的驱动，并在自动化中使用反馈进行控制，我们总结了AutoML的框架，如图6所示。与图4相比，在该图中，自动控制器代替人工来为学习工具寻找合适的配置。基本上，我们在控制器中有两个关键组件，即优化器和评估器。

![](/img/image_process/36.png)

    AutoML通过问题设置和技术来处理分类法，其灵感来自图6中建议的框架。按问题设置分类取决于我们使用的学习工具，它阐明了我们想让什么自动化;按技术分类取决于我们如何解决自动化问题。具体来说，特征工程、模型选择和优化算法选择共同构成了一般机器学习应用的全部范围(图1)。

它们与图6中其他组件的交互如下:

+ 评估器:**评估器的职责是使用优化器提供的配置来度量学习工具的性能**。然后，它生成反馈给优化器。通常，为了在给定配置下测量学习工具的性能，评估器需要基于输入数据训练模型，这可能很耗时。然而，评估器也可以直接基于外部知识来评估绩效，这是模仿人类经验的。这种估计非常快，但可能不准确。因此，对于评估器来说，它需要在测量配置性能时既高效又准确。
+ 优化器:然后，对于优化器，它的职责是更新或生成学习工具的配置。优化器的搜索空间是由目标学习过程决定的，新配置的性能有望优于以前的配置。然而，评估器提供的反馈不一定是必需的，优化器也不一定利用这些反馈。这取决于我们使用的优化器的类型。最后，根据学习过程和相应的搜索空间选择优化器，搜索空间决定了不同优化方法的适用性。我们也希望搜索空间的结构能够简单紧凑，以便使用更通用和有效的优化方法。

我们将看到，这个框架足够通用，可以涵盖几乎所有现有的工作。此外，这个框架还足够精确，可以帮助我们为AutoML方法设置分类法，并为AutoML的未来方向提供了洞察。

#### **2.3 AutoML方法的分类**

在本节中，我们将根据自动化的内容和方式给出现有AutoML方法的分类。

"什么是自动化":通过问题设置

学习工具(机器学习算法)的选择激发了基于图5(a)中的问题设置的分类法，这**定义了我们想让AutoML自动化的内容**。对于一般的学习问题，基本上需要进行特征工程、模型选择和优化算法选择。这三个部分一起构成了一般机器学习应用程序的全部范围(图1)。原因在于NAS针对的是深度模型，其中同时配置了特征、模型和算法。

"如何自动化":通过技术

图5(b)显示了AutoML技术的分类。这些是用于控制器的技术，并对我们如何解决自动化问题进行分类。一般来说，我们将现有的技术分为基本技术和经验技术

+ 基本技术:因为有两种成分，即在控制器中，我们根据操作的成分对基本技术进行分类。优化器侧重于搜索和优化配置，有很多方法可以使用，从简单的网格搜索和随机搜索，到更复杂的强化学习和自动微分。然而，对于主要通过确定学习工具的参数来衡量当前配置下学习工具性能的**评估器**来说，作为基本方法的方法并不多。
+ 经验技术:经验技术从过去的搜索或外部数据中学习和积累知识。它们通常需要与基本技术相结合，并以各种方式增强优化器和/或评估器。一般来说，AutoML中常用的方法有两种，即，元学习、和迁移学习。

注意，由于E、T和P也涉及到AutoML定义(定义2)，机器学习的分类，如监督学习、半监督学习和非监督学习，也可以应用于AutoML。然而，它们并不一定与在查找配置时删除人工辅助联系在一起(图4)，因此，这里的分类是基于图6中建议的框架来完成的。最后，由于AutoML现有的所有工作都是有监督的，所以我们在本次调查中重点关注有监督的自动方法。

Workflow based on Taxonomies

## 3 问题设置

在本节中，我们将详细介绍基于问题设置的分类(图5(a))。基本上，它阐明了什么需要自动化。AutoML方法不一定涵盖图1中完整的机器学习管道，它们还可以关注学习过程的某些部分。为了设置一个自动问题，应该问的常见问题是：

Remark 3.1. 设置一个自动化问题的三个重要问题是：
+ (A)我们想关注什么学习过程?
+ (B)可以设计和使用什么学习工具?(机器学习算法)
+ (C)所产生的相应构型是什么

通过回答这些问题，我们可以为AutoML方法定义**搜索空间**。表3概述了集中学习过程如何改变搜索空间。在续集中，我们将简要总结每种设置的现有学习工具以及相应的搜索空间。

![](/img/image_process/37.png)

    通过问题设置对现有自动方法进行分类。对于每个设置，我们需要选择或设计一些学习工具，然后计算出最终的配置(参见备注3.1)。

### 3.1 **Feature Engineering**

特性的质量可能是后续学习模型性能最重要的。深度学习模型的成功进一步验证了这种重要性，它可以直接从原始数据中学习特征的表示。**特征工程的自动化问题是利用数据自动构造特征**，使后续的学习工具具有良好的性能。上述目标可以进一步划分为两个子问题，即，**从数据中创建特征，增强特征识别能力**。然而，第一个问题在很大程度上取决于应用程序场景和人类的专业知识，没有从数据创建特性的通用或有原则的方法。AutoML在这个方向上只取得了有限的进展，我们将它作为一个未来的方向。目前，我们主要关注**特征增强方法**。

#### **3.1.1 特征增强方法**

在很多情况下，数据中的原始特征可能不够好，例如，它们的维数可能过高，或者样本在特征空间中可能无法识别。因此，我们可能需要对这些特性进行一些后处理来提高学习性能。幸运的是，虽然仍然需要人工帮助，**但是有一些通用的方法和原则方法来增强特性**。它们列在下面：

+ 降维:是通过获得一组主变量来减少考虑的随机变量数量的过程。当特征具有较大的冗余度或特征维数过高时，降维是有用的。这类技术可以分为特征选择和特征投影。特性选择尝试从原始特性中选择一个子集，其中流行的方法是贪婪搜索和lasso。特征投影将原始特征转换为新的低维空间，如PCA、LDA，以及最近开发的自动编码器。
+ 特征生成:未探索的原始特征之间的交互，一旦发现，可以显著提高学习性能。**特征生成是在原有特征的基础上，基于一些预定义的操作来构造新的特征**，如两个特征的乘法和标准归一化。
+ 特征编码:最后一类是特征编码，它根据从数据中学习到的一些词典对原始特征进行重新解释。由于字典能够在训练数据中捕捉到协作表示，使得在原始空间中无法识别的训练样本在新的空间中可以分离。这类常见的例子有稀疏编码[34](及其卷积变体)和局部线性编码[74]。此外，内核方法也可以看作是特征编码，其中基函数充当字典。然而，支持向量机必须使用核方法，基函数是手工设计的，不受数据驱动。

虽然对于使用上述特性增强工具有一些实用的建议，但是在面对新的任务时，我们仍然需要尝试和测试。

#### **3.1.2 搜索空间**

对于上述特性增强工具，有两种类型的搜索空间。**第一个是由这些工具的超参数组成**，配置就是指这些超参数。它包括降维和特征编码方法。例如，在使用PCA时，我们需要确定特征的维数，如果使用稀疏编码，则需要确定稀疏性的级别。第二种搜索空间包含**要生成和选择的特征**。它在特征生成中通常被考虑。基本上，搜索空间是由对原始特征的操作扩展的。图8显示了由加号、减号和乘号操作生成的新特性的一个示例。对于这些方法，配置是搜索空间中新生成的特征。

![](/img/image_process/38.png)

![](/img/image_process/40.png)

    给出了模型选择的搜索空间，其中考虑了KNN、线性SVM和贝叶斯分类器。c:表示超参数是连续的，d:表示超参数是离散的。在该图中，通过选择KNN分类器及其对应超参数中的值组成配置。

### **3.2 Model Selection**

一旦获得特征，我们需要找到一个模型来预测标签。模型选择包含两个组件，即，**选取一些分类器并设置相应的超参数**。在这种自动设置中，任务是**自动选择分类器并设置它们的超参数**，从而获得良好的学习性能。

#### **3.2.1 Classification Tools**

文献中提出了许多分类工具，如树分类器、线性分类器、核机器以及最近提出的深度网络。每个分类器在数据下的建模都有自己的优缺点。表4列出了在scikit-learn中实现的一些开箱即用的分类器。可以看出，每个分类器都有不同的超参数。传统上，不同分类器之间的选择及其超参数通常是由经验丰富的人通过反复试验来确定的。

![](/img/image_process/39.png)

    例子分类器在Scikit-Learn及其超参数。通常，超参数可以是(a)离散的，例如kNN中的近邻数，或者(b)连续的。例如，logistic回归中的惩罚值。

#### **3.2.2 Search Space**

在模型选择上下文中，候选分类器及其对应的超参数构成了搜索空间。图9显示了一个通常用于表示搜索空间的层次结构。这种结构背后的原理是，只有在考虑相应的分类器时，才需要确定超参数。

### 3.3 **优化算法的选择**

机器学习的最后一个也是最耗时的步骤是模型训练，通常涉及优化。对于经典的学习模型，优化并不需要考虑，因为它们通常使用凸损失函数，从各种优化算法中得到的性能几乎相同。因此，效率是优化算法选择的重点。然而，随着学习工具的日益复杂，如SVM到深度网络，优化不仅是计算预算的主要消费者，而且对学习性能有很大的影响。因此，算法选择的目标是自动找到一个优化算法，使效率和性能达到平衡。

#### **3.3.1 Optimization Algorithms**

对于每种学习工具，都可以使用许多算法。表5总结了一些常用的最小化光滑目标函数的方法，如logistic回归。梯度下降法(GD)不需要额外的参数，但收敛速度慢，迭代复杂度高。GD的两种常见变体是有限内存bfgs (L-BFGS)和随机梯度下降(SGD)。前者代价更高，但收敛速度更快，而后者每次迭代都非常便宜，但在收敛之前需要多次迭代。

![](/img/image_process/41.png)

#### **3.3.2 搜索空间**

传统上，优化算法及其超参数的选择都是由人类基于对学习工具的理解和对训练数据的观察而做出的。为了实现算法选择的自动化，**搜索空间由优化算法的配置**决定，其中包含优化算法的选择及其超参数值。在这样的搜索空间中自然也有一个层次结构，类似于图9所示，因为只有选择了相应的算法，才会考虑算法的超参数。

### **3.4 Full Scope**

在本节中，我们将讨论图1中的完整pipeline。通常有两类全范围自动方法。

+ 第一个是一般情况。这种情况下考虑的学习过程是特征工程、模型选择和算法选择的结合。所得到的搜索空间也是3.1-3.3节中所讨论的搜索空间的集合
+ 第二种是NAS，它的目标是**搜索适合学习问题的良好的深度网络架构**。我们在全面讨论这一问题时，主要有三个理由。首先，NAS本身目前是一个非常热门的研究课题，已经发表了许多相关论文。第二个原因是深层网络的应用领域相对清晰，即，从低语义级数据(如图像像素)学习的领域。最后，由于应用领域是清晰的，特定领域的网络架构可以实现学习目的，其中**特性工程和模型选择都由NAS完成**

#### **3.4.1 网络架构搜索(NAS)**

在描述NAS的搜索空间之前，让我们先看看卷积神经网络(CNN)的典型架构是什么。如图10所示，CNN基本上由两部分组成，即，一系列卷积层和最后一个完全连接的层。

![](/img/image_process/42.png)

CNN的性能主要受卷积层的设计影响，图11中列出了一些常见的设计选择。搜索空间由上述所有卷积层之间的设计选择组成，NAS的一个配置就是这样一个搜索空间中的一个点。

在众多的DNN架构中，我们在本次调查中主要关注CNN，但是所提出的思想同样适用于其他架构，如长短时记忆(LSTM)和深度稀疏网络

![](/img/image_process/43.png)

## **4 优化器的基本技术**

一旦定义了搜索空间，如在建议的框架中（图6），我们需要找到一个优化器来指导空间中的搜索。 在本节中，我们将讨论优化器的基本技术。

**备注4.1**。这里的三个重要问题是
+ (A)优化器可以在什么样的搜索空间上运行?
+ (B)它需要什么样的反馈?
+ (C)在找到一个好的配置之前，需要生成/更新多少配置

前两个问题确定可以为优化器使用哪种类型的技术，最后一个问题阐明了技术的效率。虽然效率在AutoML中是一个主要的关注点，但是在本节中，我们没有基于它对现有技术进行分类。这是因为搜索空间非常复杂，每种技术的收敛速度都很难分析。同时，经验丰富的技术(第6节)可以以各种方式加速基本的技术。因此，在续集中，我们将这些技术分为三类，即，**简单的搜索方法，从样本优化，梯度下降**，基于前两个问题。表6概述了这些技术之间的比较。

### **4.1简单搜索方法**

简单搜索是一种幼稚的搜索方法，它们对搜索空间没有任何假设。搜索空间中的每个配置都可以独立计算。网格搜索和随机搜索是两种常用的搜索方法。

+ *网格搜索(蛮力)*:这是最传统的超参数调优方法。为了得到最优的超参数设置，网格搜索必须枚举搜索空间中所有可能的配置。当搜索空间是连续的时，离散化是必要的。
+ 随机搜索:在搜索空间中随机抽取配置样本。随机搜索在经验上比蛮力网格搜索有更好的性能。如图12所示，与网格搜索相比，随机搜索可以在更重要的维度上进行探索。

简单的搜索方法从评估器收集反馈，仅仅是为了跟踪好的配置。由于简单搜索不利用从过去评估中获得的知识，因此通常效率低下。然而，由于它的简单性，它仍然在AutoML中广泛使用。

![](/img/image_process/44.png)

    用二维搜索问题中的9次试验说明网格和随机搜索。该图还说明，在试验次数相同的情况下，随机搜索比网格搜索做的探索更多。

### **从样本优化**

与4.1节中简单的搜索方法相比，样本优化是一种更智能的搜索方法。**它根据先前评估的示例迭代地生成新的配置**。因此，它通常也比简单的搜索方法更有效。此外，它没有对目标做出具体的假设。在续集中，我们根据不同的优化策略，将现有的方法分为三类:**启发式搜索、基于模型的无派生优化和强化学习**。

#### **4.2.1启发式搜索**

启发式搜索方法常常受到生物行为和现象的启发。它们广泛用于求解非凸、非光滑、甚至非连续的优化问题。其中大多数是基于种群的优化方法，不同之处在于如何生成和选择种群。启发式搜索的框架如图13所示。初始化步骤生成第一个总体(AutoML中的一组配置)。在每个迭代中，基于最后一个种群生成一个新的种群，并评估个体的适应度(性能)。启发式搜索的核心思想是如何更新种群。

![](/img/image_process/45.png)

一些流行的启发式搜索方法如下:

+ 粒子群优化(PSO): PSO的灵感来自生物群落的行为，表现出个体和社会行为;这些群落的例子有鸟群、鱼群和成群的蜜蜂。这些社会的成员有共同的目标(例如，寻找食物)，这些目标是通过探索其环境和相互作用来实现的。在每次迭代中，通过向最佳个体移动来更新总体。PSO通过搜索最佳样本的邻域来优化。它本身有几个超参数，可以很容易地并行化。这样，PSO希望在搜索空间中找到最好的位置。
+ 进化算法:进化算法受到生物进化的启发。进化算法的生成步骤包括交叉和变异。交叉涉及上一代的两个不同的个体(祖先)。它以某种方式把它们结合起来，产生一个新的个体。从原则上讲，一个人越有前途，他被选为祖先的可能性就越大。另一方面，突变会轻微地改变个体以产生新的个体。以交叉为主开发，以变异为主探索，期望种群进化出更好的性能。


上述方法在AutoML中得到了广泛的应用。例如，进化算法已经应用于特征选择和生成，模型选择。PSO用于模型选择，支持向量机(SVM)的特征选择，深度网络的超参数整定。虽然进化算法已经在NAS中使用了10年，但是直到最近才实现了比人类设计的体系结构性能更好的。在这些工作中，网络结构用二进制字符串编码，在二进制字符串上执行进化操作。

####　**4.2.2基于模型的无派生优化**

基于模型的无派生优化的一般框架如图14所示。与启发式搜索不同的是，基于模型的优化是在访问样本的基础上建立模型的。充分利用评估者的反馈有助于生成更有前途的新样本。目前流行的方法有贝叶斯优化、基于分类的优化和乐观优化

![](/img/image_process/46.png)

    基于模型的无派生优化工作流程。它不同于启发式搜索。基于模型的优化最重要的组成部分是建立在以前的示例基础上的模型。

+ 贝叶斯优化:贝叶斯优化建立了一个概率模型，如高斯过程，基于树的模型，或深度网络，将配置映射到具有不确定性的性能。然后，基于概率模型定义了一个获取函数，如期望改进、上置信界等，以平衡搜索过程中的勘探和开发。在每一次迭代中，通过优化采集函数生成一个新的样本，并用于对概率模型进行评估后的更新。
+ 基于分类优化(CBO):基于分类优化是在已有样本的基础上，学习**将搜索空间划分为正区域和负区域的分类器**。然后，在正区域随机生成新样本，在正区域更有可能得到更好的构型。学习的分类器可以非常简单，与搜索空间的坐标并行生成决策边界。因此，基于分类的优化通常是非常有效的。
+ 同时优化(SOO): SOO是一种分枝定界优化算法。树结构建立在搜索空间上，其中每个叶节点限定一个子区域。SOO根据一些策略，通过扩展叶节点来深入挖掘搜索空间。通过树模型，SOO可以在目标函数为局部- lipschitz连续时，平衡勘探与开发，找到全局最优。但它也受到维数的诅咒，因为当维数很高时，搜索空间会变得非常复杂。

贝叶斯优化方法具有悠久的历史和良好的理论依据，可能是这类方法中应用最广泛的一种。早期的尝试包括，这些研究表明贝叶斯优化在超参数优化方面具有很好的性能。后来在sklearn和Weka中应用，实现了开箱分类器的自动配置。近年来，在超参数优化和策略搜索方面，CBO被发展成为比贝叶斯优化更好的方法

#### **4.2.3 强化学习**

强化学习(RL)是一种非常通用和强大的优化框架，可以解决延迟反馈问题。图15演示了在AutoML中使用它的一般框架。基本上，RL中的策略充当优化器，它在环境中的实际性能由评估器度量。然而，与以前的方法不同，反馈不需要立即返回一旦采取行动。它们可以在执行一系列操作之后返回。

![](/img/image_process/47.png)

    强化学习流程。它不同于启发式搜索和基于模型的无派生优化，因为接收配置时无需立即返回反馈。

由于上述独特的性质，RL最近被用于NAS中。原因是CNN可以逐层构建，其中一层的设计可以看作是优化器给出的一个操作。然而，体系结构的性能只能在其整个结构组成之后才能进行评估，这意味着延迟的回报。因此，迭代体系结构的生成自然遵循RL的属性。然而，由于反馈延迟，带强化学习的自动机具有较高的资源消耗，需要探索更有效的方法。目前解决这个问题的一些努力是从较小的数据集学习可迁移的架构，并通过共享参数来减少搜索空间。此外，RL的一个特例，即将bandit-based的方法引入AutoML进行超参数优化和，其中每个动作都可以不延迟地返回奖励。最后，RL还被用于优化算法搜索、自动特征选择以及主动学习中的训练数据选择。

### **4.3 梯度下降**

自动机的优化问题非常复杂，目标往往是不可微的，甚至是不连续的。因此，梯度下降不如第4.2节中的方法流行。但是，针对一些可微的损失函数，如平方损失和logistic损失，可以通过梯度下降对连续超参数进行优化。与上述方法相比，梯度提供了最佳配置位置的最准确信息。不像传统的优化问题，梯度可以显式地从目标中导出，在自动问题中，梯度需要进行数值计算。通常，这可以用有限微分法来实现，但成本较高。对于一些传统的机器学习方法，如logistic回归和SVM，提出了利用近似梯度搜索连续超参数的方法。精确梯度的计算依赖于模型训练的收敛性。通过不精确梯度，在模型训练收敛前更新超参数，使梯度下降法更加有效。计算梯度的另一种方法是通过可逆学习(也称为自动微分)。该算法利用链式规则计算梯度，也用于网络训练的反向传播过程。它已被应用于深度学习超参数搜索

### **4.4 贪婪搜索**

贪婪搜索是解决多步决策问题的一种自然策略。它遵循一种启发式方法，在每一步都做出局部最优决策，目的是寻找全局最优。例如，在旅行商问题中，贪婪搜索在旅行的每一步都选择访问最近的城市。贪心搜索不能找到全局最优解，但通常能在合理的时间代价下找到近似全局最优解的局部最优解。此外，这种良好的经验性能在许多应用中也有理论依据，如特征选择和子模块优化

![](/img/image_process/48.png)

多步决策问题在自动化中也经常遇到。例如，在NAS问题中，需要确定每一层的结构，对多属性学习问题采用贪婪搜索;贪心搜索在一些论文中也被用来搜索单元格内的块结构，之后被用来构造完整的CNN。此外，在搜索空间大得令人望而却步的特征生成问题中，也有人最近考虑了贪婪搜索，以生成与原始特征更具鉴别性的特征。

最后，有一些技术不属于上述类别。它们通常是逐个开发的。目前流行的一种方法是改变搜索空间的布局，以便使用更强大的优化技术。例如，在NAS中，由于构型空间是离散的，在中使用soft-max将搜索空间变为连续的，这使得使用梯度下降代替RL;在中使用了一个编解码器框架，它也将离散的配置映射到一个连续的搜索空间。

## **基本的评估技术**

在第4部分中，我们讨论了如何为优化器选择合适的基本技术。在本节中，我们将访问另一个组件的技术，即，即图6中的评估器。一旦生成了**候选配置**，评估器就需要度量它的性能。这个过程通常是非常耗时的，因为它涉及模型训练的大部分时间。

**备注5.1**。确定评估器基本技术的三个重要问题是:
+ (A)该技术能否提供快速评估?
+ (B)这项技术能提供准确的评价吗?
+ (C)评价者需要提供什么反馈

如图17所示，问题的焦点(a)和(B)之间通常存在权衡，因为更快的评估通常会导致较差的结果，即，精度较低，但方差较大。备注5.1中的最后一个问题是设计选择，它也取决于优化器的选择。例如，如表6所示，贝叶斯优化只需要性能，梯度下降法还需要梯度信息。

![](/img/image_process/49.png)

    评价精度与时间的权衡，其中DE为直接评价(见5.1节)，时间和精度均相对于DE进行测量。灰色线表示得到的精度的方差。

### **5.1 Techniques**

与优化器不同，评估器很少关心配置的搜索空间。由于大多数优化器生成的候选项都可以直接应用到学习工具上，所以评估它们最简单直接的方法就是**学习模型参数并估计性能**:

+ 直接评价:这是最简单的方法，在训练集上学习模型参数，然后在验证集上测量性能。直接评估往往是准确的，但代价昂贵。

在自动化问题中，通常会生成许多候选配置并进行评估。直接评估方法虽然非常准确，但重复调用通常代价高昂。因此，有人提出了一些其他方法，以评估的准确性换取效率的加速

+ Sub-sampling:由于训练时间在很大程度上取决于训练数据的数量，一种直观的加速评估方法是用训练数据的子集来训练参数。这可以通过使用样本的子集、特征的子集或多保真度评估来实现。一般情况下，使用的训练数据越少，评价的速度越快，噪声越大。
+ 早停:在经典的机器学习中，早期停止是防止过度拟合的一种流行方法。然而，在AutoML的上下文中，它**通常用于减少没有希望的配置的训练时间**。在模型训练的早期阶段，通常可以很容易地识别这些配置，并在验证集上监视它们的性能。如果发现早期表现不佳，评估器可以终止训练，并报告表现不佳，表明候选没有希望。早停减少了AutoML的总运行时间，但也会给估计带来噪声和偏差，因为一些早期性能较差的配置经过足够的训练后可能最终会变成良好的
+ 参数重用(迁移学习):另一种技术是**使用以前评估中所训练模型的参数**，**为当前评估预热模型训练**。直观地说，使用类似配置学习的参数可以彼此接近。对于接近以前评估过的配置的候选，后者的参数可能是一个很好的训练起点，并可能导致更快的收敛和更好的性能。在这种情况下，参数重用非常有用。然而，由于不同的起点可能导致收敛到不同的局部最优，有时会在评价中带来偏差。
+ 代理评估器:对于易于量化的配置，降低评估成本的一种直接方法是，**根据以往评估的经验，建立一个预测给定配置性能的模型**。这些模型作为代理评估器，省去了昂贵的模型训练，并显著加快了自动化。代理评估者不仅可以预测学习工具的性能，还可以预测训练时间和模型参数。然而，它们的应用范围仅限于超参数优化，因为其他类型的配置往往难以量化，这阻碍了代理模型的训练。在第6.1节中，我们将介绍元学习技术，这些技术有望解决这个问题。最后，应该注意的是，虽然代理模型也用于基于样本的优化技术(第4.2.2节)，但它们不充当代理评估器，而是用于生成潜在的有希望的配置。

直接评估由于其简单和可靠，可能是自动测试中最常用的基本评估技术。子采样、早期停止、参数重用和代理评估器，增强了各个方向的直接评估，并可以将它们结合起来进行更快、更准确的评估。然而，这些技术的有效性和效率依赖于自动化问题和数据，相对于直接评估，很难对其改进进行定量分析。虽然评估器的基本技术看起来比优化器的技术要少得多，但这并不会降低评估器的重要性。事实上，评估器的准确性和效率对最终结果的质量和自动程序的运行时间都有很大的影响。为了使评价者更强大，在AutoML中引入了基于元学习和转移学习的各种技术。它们将在第6节中讨论。

## **6 EXPERIENCED TECHNIQUES**

在第2.2节中，我们讨论了为给定的学习问题自动构建学习工具的一般框架。该框架突出显示了一个搜索过程，该过程包括配置生成和评估。在本节中，我们将回顾一些经验丰富的技术，这些技术可以将它们放入我们提出的框架中，从而提高AutoML的效率和性能。本节的两个主要主题是:**1)元学习**，提取关于学习的元知识，训练元学习者指导学习;**2)迁移学习**，从过去的经验中获取可转移的知识，帮助未来的学习。

**备注6.1**。值得注意的是，元学习的范围与迁移学习的范围是重叠的，因为它们都旨在利用过去学习实践中获得的经验。此外，对元学习没有统一的定义，一些研究者也将迁移学习作为元学习的特例。关于元学习和迁移学习之间的内在相似性和差异性的讨论超出了本调查的范围。在这里，我们用以下标准来区分它们:一种方法是元学习，如果它从过去的学习中提取关于学习问题和工具(例如元特性和性能)的元知识，并训练元学习者为将来提供便利;否则，如果它直接使用过去学习的最终或中间结果(例如，最佳配置或代理模型)，那么它就是一个迁移学习方法。请比较图18和图19。

### **6.1 元学习**

**元学习一般是从过去的经验中学习特定的学习工具如何处理给定的问题，目的是为即将出现的问题推荐或构建有前景的学习工具**。元学习与自动机有着密切的联系，因为它们有着相同的学习目标，即学习工具和学习问题。在本节中，我们将首先简要介绍元学习的一般框架，并解释为什么以及如何使用元学习来帮助AutoML。然后，我们回顾了现有的元学习技术，根据它们在AutoML中的应用将它们分为三类:1)用于配置评估的元学习(用于评估者);2)用于配置生成的元收益(用于优化器);3)用于动态配置适应的元学习。

![](/img/image_process/50.png)

#### **6.1.1 一般的元学习框架**

元学习满足机器学习的定义(定义1)，但它与经典机器学习的显著不同之处在于，元学习的目标是完全不同的任务，因此，它从不同的经验中学习。表8给出了元学习和经典机器学习之间的类比，说明了它们之间的异同。与经典的机器学习一样，元学习是通过从经验中提取知识，基于知识培训学习者，并将学习者应用于即将出现的问题来实现的。图18展示了元学习的一般框架。首先，对学习问题和学习工具进行了描述。这些特征(如数据集的统计特性、学习工具的超参数)通常被称为元特征，然后，从过去的经验中提取元知识。除了元特性之外，还需要关于元学习目标的经验知识，例如学习工具的性能或针对特定问题的有前景的工具。然后，用元知识训练金属工人。大多数现有的机器学习技术，以及简单的统计方法，都可以用来生成元学习者。训练有素的元学习者可以应用于即将到来的、具有特征的学习问题，从而做出有趣的预测。

![](/img/image_process/51.png)

![](/img/image_process/52.png)

元学习通过描述学习问题和工具来帮助自动学习。这些特征可以揭示关于问题和工具的重要信息，例如，数据中是否存在概念漂移，或者模型是否适合特定的机器学习任务。此外，利用这些特性，可以评估不同任务和工具之间的相似性，从而实现不同问题之间的知识重用和转移。一种简单但广泛使用的方法是，在元特征空间中使用任务邻域的经验最佳配置为新任务推荐配置。另一方面，元学习者对过去的经验进行编码，并作为解决未来问题的指导。一旦经过训练，元学习者就可以快速评估学习工具的配置，从而省去了对模型进行计算性的昂贵训练和评估。它们还可以生成有希望的配置，这些配置可以直接指定一个学习工具，或者作为搜索的良好初始化，或者建议有效的搜索策略。因此，元学习可以大大提高自动学习方法的效率。为了将元学习应用到AutoML中，我们需要明确元学习的目的，以及相应的元知识和元学习者，如Remark 6.2所述。

后续待更新。。。。